---
layout: post
title: 'K-fold Cross Validation (with HRA Data)'
date: 2017-02-01
author: Yin-Ting 
categories: [Methodology, R]
tags: [sampling]
---
For the purpose of avoiding overfitting and incresing model stability, K-fold Cross Validation sampling method should be applied before all the model fitting. There are two steps for the K-fold Cross Validation. First, decide the proportion for the train, validation and test set[^1]. Second, decide the number of fold, K[^2]. 

[^1]: In this project, I subjectively decide to set 70% for the train set; 20% for the validation and 10% for the test set. 

```{r}
dat=read.csv("https://choux130.github.io/myblog/data/HR_analytics.csv",
             header=TRUE)
data=dat # keep raw data pure
names(data)=c("satisf_level","last_eval","num_proj",
              "ave_mon_hrs","time_spend","work_accid",
              "left_or_not","promo_last_5yrs","department",
              "salary")
data=data[,c(1:6,8:10,7)]
data[,c("work_accid","promo_last_5yrs","left_or_not")]=
  lapply(data[,c("work_accid","promo_last_5yrs","left_or_not")],as.factor)
```

### The function for seperate data into two parts based on proportion
```{r}
cv2=function(data, prop1){
  N = nrow(data)
  n = ceiling(N*prop1)
  ind = sample(N,n)
  sep1= data[ind,]
  sep2= data[-ind,]
  
  list(dat_1=sep1, dat_2=sep2)
}
```

```{r}
# This is the test set which will only be used in the model selection part. 
test=cv2(data,0.9)$dat_2 #1499   10
```

[^2]: Let K=10

```{r}
k=10
data$cv_group=sample(rep(1:k, length.out=nrow(data)), 
                     nrow(data), replace=FALSE)

# the fold 1 validation set
first_val=data[data$cv_group=="1",]
# the fold 1 train set 
first_train=data[data$cv_group!="1",]
```
